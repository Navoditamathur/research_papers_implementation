{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook uses Diffusion  model trained on MNIST dataset to generate the images."
      ],
      "metadata": {
        "id": "sEEvqUZ15AQH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HOJ-r9LeZd_q"
      },
      "outputs": [],
      "source": [
        "#Libraries importing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implement a unet problem\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.encoder(x)\n",
        "        x2 = self.middle(x1)\n",
        "        x3 = self.decoder(x2)\n",
        "        return x3\n"
      ],
      "metadata": {
        "id": "C9F4Bs8bbl9O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 100  # Reduced for demonstration\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "timesteps = 1000\n",
        "\n",
        "# Model, Loss Function, Optimizer\n",
        "model = UNet().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Dataloader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='.', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "gAP7O1upb1-c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "betas = linear_beta_schedule(timesteps)\n",
        "alphas = 1 - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "\n",
        "def forward_diffusion_sample(x_0, t, device):\n",
        "    noise = torch.randn_like(x_0)\n",
        "    sqrt_alphas_cumprod_t = torch.sqrt(alphas_cumprod[t.cpu()]).view(-1, 1, 1, 1).to(device)\n",
        "    sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1 - alphas_cumprod[t.cpu()]).view(-1, 1, 1, 1).to(device)\n",
        "    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise, noise\n"
      ],
      "metadata": {
        "id": "iwpeA66gg4TH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, epochs, timesteps):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        loop = tqdm(train_loader, leave=False)\n",
        "        for batch_idx, (data, _) in enumerate(loop):\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Sample a random timestep for each image\n",
        "            t = torch.randint(0, timesteps, (data.size(0),), device=device).long()\n",
        "            x_noisy, noise = forward_diffusion_sample(data, t, device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(x_noisy)\n",
        "            loss = criterion(output, noise)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            loop.set_description(f'Epoch [{epoch+1}/{epochs}]')\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Save model checkpoint\n",
        "        torch.save(model.state_dict(), f'checkpoint_epoch_{epoch+1}.pth')\n",
        "        # Save example generated images\n",
        "        save_image(x_noisy[:25], f'noisy_epoch_{epoch+1}.png', nrow=5, normalize=True)\n",
        "\n",
        "train(model, train_loader, optimizer, criterion, epochs, timesteps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ1KAozYb3Ri",
        "outputId": "2721af60-b7bd-4686-c98e-a074933881ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_step(model, x, t, betas, device):\n",
        "    t = torch.tensor([t]).to(device)\n",
        "    sqrt_recip_alphas_t = torch.sqrt(1 / alphas[t.cpu()]).to(device)\n",
        "    sqrt_recipm1_alphas_t = torch.sqrt(1 / alphas[t.cpu()] - 1).to(device)\n",
        "    pred_noise = model(x)\n",
        "    x = sqrt_recip_alphas_t * (x - sqrt_recipm1_alphas_t * pred_noise)\n",
        "    return x\n",
        "\n",
        "def generate_images(model, num_images, steps, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_images):\n",
        "            x = torch.randn(1, 1, 28, 28).to(device)\n",
        "            for step in range(steps, 0, -1):\n",
        "                x = denoise_step(model, x, step-1, betas, device)\n",
        "            save_image(x, f'generated_image_{i+1}.png', normalize=True)\n",
        "\n",
        "# Load the trained model\n",
        "model.load_state_dict(torch.load('checkpoint_epoch_100.pth'))\n",
        "model = model.to(device)\n",
        "\n",
        "# Generate new images\n",
        "generate_images(model, num_images=10, steps=timesteps, device=device)\n"
      ],
      "metadata": {
        "id": "83suulEicGn-"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}